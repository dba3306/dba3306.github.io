<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[mongodb writeConcern初探]]></title>
      <url>/mongodb/2020/04/20/mongodb-writeConcern/</url>
      <content type="text"><![CDATA[什么是writeConcernwriteConcern 决定一个写操作落到多少个节点上才算成功。取值包括：  0 ：发起写操作，不关心是否成功。  1~集群最大节点数 ：写操作需要复制到指定节点数才算成功  majority：写操作需要复制到多数节点才算成功发起写操作的程序将阻塞直到满足上诉条件。  writeConcern类似MySQL的半同步复制--rpl-semi-sync-master-wait-for-slave-count这里还要提到另一个概念：Journal 日志，跟MySQL的redo log类似，也是为了做crash safe。为了保证每次写数据都落盘，可以指定j: true注：3.2之前只要primary节点落盘就确认ok，3.2之后需要w:N都确认才okwriteConcern功能验证w: “majority”rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: "majority"}})WriteResult({ "nInserted" : 1 })这是推荐的写法，mongodb会自己判断只要写入多数节点即返回成功w: 节点数rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3 }})WriteResult({ "nInserted" : 1 })可以看到正常情况下（secondary节点没延迟）也很快返回成功了。w＞节点数rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 4}})WriteResult({        "nInserted" : 1,        "writeConcernError" : {                "code" : 100,                "codeName" : "UnsatisfiableWriteConcern",                "errmsg" : "Not enough data-bearing nodes"        }})这里虽然报错了，但实际还是写入成功了。secondary节点有延迟的情况下，观察现象首先我们模拟延迟场景，在primary节点执行，模拟secondary 2节点延迟10秒conf=rs.conf() conf.members[2].slaveDelay = 10conf.members[2].priority = 0 rs.reconfig(conf)观察复制延迟下的写入，以及timeout参数db.test.insert( {count: 1}, {writeConcern: {w: 3}})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3}})# 这里会等待10sWriteResult({ "nInserted" : 1 })rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }db.test.insert( {count: 1}, {writeConcern: {w: 3, wtimeout:3000 }})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3, wtimeout:3000 }})# 这里等3s后报错，实际命令敲下的一瞬间已写入到primary和没延迟的secondary，延迟节点需要等10s后落盘。WriteResult({        "nInserted" : 1,        "writeConcernError" : {                "code" : 64,                "codeName" : "WriteConcernFailed",                "errmsg" : "waiting for replication timed out",                "errInfo" : {                        "wtimeout" : true                }        }})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }{ "_id" : ObjectId("5e9d800ed4eb493af10599cd"), "count" : 1 }总结  虽然多于半数的writeConcern都是安全的，但通常只会设置majority，因为这是等待写入延迟时间最短的选择;  不要设置writeConcern等于总节点数，因为一旦有一个节点故障，所有写操作都将失败;  writeConcern虽然会增加写操作延迟时间，但并不会显著增加集群压力，因此无论是否等待，写操作最终都会复制到所有节点上。设置 writeConcern 只是让写操作等待复制后再返回而已;  应对重要数据应用{w:“majority”}，普通数据可以应用{w:1}以确保最佳性能。]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb复制集环境搭建]]></title>
      <url>/mongodb/2020/04/20/mongo_replset_building/</url>
      <content type="text"><![CDATA[  目标：在mac上部署3个节点的复制集，为后续测试准备环境创建目录：mkdir -p /data/mongodb/db{1,2,3}编辑配置文件：cat /data/mongodb/db1/mongod.conf systemLog:    destination: file    path: /data/mongodb/db1/mongod.log    logAppend: truestorage:    dbPath: /data/mongodb/db1net:    bindIp: 0.0.0.0    port: 28017replication:    replSetName: rs0processManagement:    fork: true  其他节点只需修改path和port即可启动mongod：mongod -f /data/db1/mongod.conf配置复制集：mongo --port 28017  方法一&gt; rs.initiate()&gt; rs.add("HOSTNAME:28018") &gt; rs.add("HOSTNAME:28019")  方法二mongo --port 28017&gt; rs.initiate({    _id: "rs0",    members: [    {_id: 0,host: "localhost:28017" },    {_id: 1,host: "localhost:28018" },    {_id: 2,host: "localhost:28019" }    ]})验证  MongoDB 主节点进行写入mongo localhost:28017&gt; db.test.insert({ a:1 })&gt; db.test.insert({ a:2 });  MongoDB 从节点进行读mongo localhost:28018&gt; rs.slaveOk()&gt; db.test.find()]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[一些运维常用的SQL]]></title>
      <url>/%E8%BF%90%E7%BB%B4/mysql/2020/04/18/mysql_sql/</url>
      <content type="text"><![CDATA[delete from xxx order by xxx limit xx,xx;背景：执行如下sqlDELETE FROM table WHERE type = 'test' ORDER BY id DESC LIMIT 30, 60;报错：#1064 - You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near ' 60' at line 1解决：DELETE FROM tableWHERE ID IN        (        SELECT ID        FROM            (                SELECT ID                FROM table                WHERE Type = 'TEST'                ORDER BY ID                LIMIT 30,60            ) a        )mysqlbinlog  查看mysqlbinlog -vv --base64-output=decode-rows  binlogfile  恢复mysqlbinlog master.000001  --start-position=2738 --stop-position=2973 | mysql -h127.0.0.1 -P13000 -u$user -p$pwd;统计包含某列的所有表select TABLE_SCHEMA,TABLE_NAME,group_concat(COLUMN_NAME,' ',COLUMN_DEFAULT,' ',EXTRA Separator ',') from information_schema.columns where TABLE_SCHEMA IN ( 'iccs_loan', 'opr','stdcmp','saas' ) and COLUMN_NAME in ('sync_insTime','sync_lastUptTime') group by TABLE_SCHEMA,TABLE_NAME;统计非法字符集和排序的表select TABLE_schema,TABLE_NAME,group_concat(concat_ws('/',COLUMN_NAME,CHARACTER_SET_NAME,COLLATION_NAME)) as `sql` from information_schema.columns where TABLE_SCHEMA IN ( 'iccs_loan', 'opr','stdcmp','saas' ) and (CHARACTER_SET_NAME !="utf8mb4" or COLLATION_NAME !="utf8mb4_bin") group by TABLE_schema,TABLE_NAME\G修改表字符集alter table xxx modify xxx varchar(xxx) NOT NULL collate utf8mb4_bin COMMENT 'xxx';快速查看processlistmysqladmin --login-path=qaroot pr|grep -v Sleep时间相关  一小时前CREATE_TIME &lt; (UNIX_TIMESTAMP(DATE_ADD(NOW(),INTERVAL -1 HOUR))*1000);  3小时前(后)TIMESTAMPDIFF(hour,FROM_UNIXTIME( UPDATE_TIME / 1000, '%Y-%m-%d %T' ),NOW()) &gt; 3mysqldumpmysqldump -u root -p --all --single-transaction --triggers --routines --events &gt;/data/dbbackup/full_backup.sql]]></content>
      <categories>
        
          <category> 运维 </category>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 运维 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[用innobackupex实现加密备份]]></title>
      <url>/mysql/2020/04/18/innobackupex_encrypt/</url>
      <content type="text"><![CDATA[安装innobackupexyum install https://repo.percona.com/yum/percona-release-latest.noarch.rpmyum install percona-xtrabackup-24MySQL创建备份用户GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'xbackupopr'@'%' IDENTIFIED BY 'UFfrBrtyv_cxR50C';生成encrypt-key（可不执行，直接用脚本中的key）openssl enc -aes-256-cbc -pass pass:Password -P -md sha1 | grep iv | cut -d'=' -f2 脚本#!/usr/bin/python#coding:UTF-8import os,time,sys,commandsinnobackupex = '/usr/bin/innobackupex'# 全备函数def full_backup(host, port, user, password, full_backup_dir,week_of_dir, backup_log):    os.system("%s --host=%s --port=%s --user=%s --password=%s --encrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7 --extra-lsndir=%s --no-timestamp %s &gt; %s 2&gt;&amp;1" %(innobackupex,host, port, user, password, week_of_dir,full_backup_dir, backup_log))# 增备函数def incr_backup(host, port, user, password, incr_backup_dir, incremental_lsn,extra_lsndir,backup_log):    os.system("%s --incremental %s  --incremental-lsn=%s --host=%s --port=%s --user=%s --password=%s  --extra-lsndir=%s --encrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7 &gt; %s 2&gt;&amp;1" %(innobackupex,incr_backup_dir,incremental_lsn,host,port,user,password,extra_lsndir,backup_log))# 主函数if __name__ == '__main__':    host = "127.0.0.1"    port = '3306'    user = 'xbackupopr'    password = 'UFfrBrtyv_cxR50C'    backup_dir = '/data/backup/'    defaults_file = '/data/my3306/my.cnf'    wday = time.localtime().tm_wday    week_of_dir = backup_dir + time.strftime("%U", time.localtime())    full_backup_dir = week_of_dir + '/full'    backup_log = "/tmp/backup.log"    # 增备寻找最新的上一次备份的基准目录    base_backup_dir = commands.getoutput('find ' + week_of_dir + ' -mindepth 1 -maxdepth 1 -type d -printf "%P\n"  | sort -nr | head -1')     # 获取最新的lsn,xtrabackup_checkpoints文件在每次全备或者增备后会被覆盖    if os.path.exists(week_of_dir + '/xtrabackup_checkpoints'):        incremental_lsn = commands.getoutput('cat ' + week_of_dir + '/xtrabackup_checkpoints| grep to_lsn | cut -d"=" -f2|sed -e "s/^[ ]*//g"')        print(incremental_lsn)    else:        print('xtrabackup_checkpoints not exists.Maybe full_backup progress not running yet.')    # 探测mysql实例是否存活，如果存活继续下面的程序执行，如果不存活则直接退出程序    mysql_stat = commands.getoutput('/bin/netstat -anp|grep ' + port + ' |grep -v unix|wc -l')    if mysql_stat &gt;= 1:        print "mysql实例存活，可进行备份操作！"    else:        print "mysql实例不存在，备份操作终止！"        sys.exit()    # 每周生成一个周备份目录，全备和增备目录都放在此目录下面    if os.path.exists(week_of_dir):        print "周备份目录已经生成，可进行相应的全备或者增量备份"    else:        print "周备份目录未产生，创建周备份目录..."        os.makedirs(week_of_dir)    # 判断是否周日，如果是周日，直接进行全备，如果不是周日，先检查全备是否存在，不存在则进行全备，存在则进行增备    print "备份开始"    if wday == 6:        full_backup(host, port, user, password, full_backup_dir, week_of_dir,backup_log)    else:        if os.path.exists(full_backup_dir):            incr_backup(host, port, user, password, week_of_dir,incremental_lsn,week_of_dir,backup_log)        else:            full_backup(host, port, user, password, full_backup_dir,week_of_dir, backup_log)    print "备份结束，判断备份是否成功"    try:        with open("/tmp/backup.log") as f:            f.seek(-14, 2)            backup_results = f.readline().strip()            if backup_results == "completed OK!":                print "备份成功"            else:                print "备份失败"                except Error:        sys.exit()    # 备份保留4周    os.system("find %s -mindepth 1 -maxdepth 1 -type d -ctime +28 -exec rm -rf  {} \;" %backup_dir) 备份解密innobackupex  --decrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7  /data/backup/42/full/]]></content>
      <categories>
        
          <category> mysql </category>
        
      </categories>
      <tags>
        
          <tag> pt-tools </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
