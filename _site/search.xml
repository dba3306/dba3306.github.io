<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[快速搭建innodb cluster 集群]]></title>
      <url>/%E8%BF%90%E7%BB%B4/mysql/2020/04/22/mac%E4%B8%8A%E7%94%A8dbdeploy%E9%83%A8%E7%BD%B2MiC%E9%9B%86%E7%BE%A4/</url>
      <content type="text"><![CDATA[用dbdeployer 部署3个单节点dbdeployer deploy multiple 5.7 -n 3查看节点状态dbdeployer sandboxes --full-info.------------------.----------.---------.-----------.----------------------.--------.-------.--------.|       name       |   type   | version |   host    |         port         | flavor | nodes | locked |+------------------+----------+---------+-----------+----------------------+--------+-------+--------+| multi_msb_5_7_29 | multiple | 5.7.29  | 127.0.0.1 | [24630 24631 24632 ] | mysql  |     3 |        |'------------------'----------'---------'-----------'----------------------'--------'-------'--------'dbdeployer global status# Running "status_all" on multi_msb_5_7_29MULTIPLE  /Users/qianyin/sandboxes/multi_msb_5_7_29node1 : node1 on  -  port       24630 (24630)node2 : node2 on  -  port       24631 (24631)node3 : node3 on  -  port       24632 (24632)下载MySQL-Shellwget https://dev.mysql.com/get/Downloads/MySQL-Shell/mysql-shell-8.0.19-macos10.15-x86-64bit.tar.gz解压后进入mysql shell 目录bin目录下就3个文件-rwxr-xr-x@ 1 qianyin  staff    633256 12 17 09:42 mysql-secret-store-keychain*-rwxr-xr-x@ 1 qianyin  staff   7957420 12 17 09:42 mysql-secret-store-login-path*-rwxr-xr-x@ 1 qianyin  staff  31067132 12 17 09:42 mysqlsh*我们运行mysqlsh可以先打\help 看下帮助提示可以看到支持的模块如下： - dba    Used for InnoDB cluster administration. - mysql  Support for connecting to MySQL servers using the classic MySQL          protocol. - mysqlx Used to work with X Protocol sessions using the MySQL X DevAPI. - os     Gives access to functions which allow to interact with the operating          system. - shell  Gives access to general purpose functions and properties. - sys    Gives access to system specific parameters. - util   Global object that groups miscellaneous tools like upgrade checker          and JSON import.部署集群我们需要用到dba功能，再查看dba的帮助信息\? dba正式配置集群检查并配置3个数据库实例mysql-js&gt; \connect root@localhost:24630 MySQL  localhost:24630 ssl  JS &gt; dba.configureLocalInstance()Configuring local MySQL instance listening at port 24630 for use in an InnoDB cluster...This instance reports its own address as node-1:24630ERROR: User 'root' can only connect from 'localhost'. New account(s) with proper source address specification to allow remote connection from all instances must be created to manage the cluster.1) Create remotely usable account for 'root' with same grants and password2) Create a new admin account for InnoDB cluster with minimal required grants3) Ignore and continue4) CancelPlease select an option [1]: Please provide a source address filter for the account (e.g: 192.168.% or % etc) or leave empty and press Enter to cancel.Account Host: %NOTE: Some configuration options need to be fixed:+----------------------------------+---------------+----------------+------------------------------------------------+| Variable                         | Current Value | Required Value | Note                                           |+----------------------------------+---------------+----------------+------------------------------------------------+| binlog_checksum                  | CRC32         | NONE           | Update the server variable and the config file || enforce_gtid_consistency         | OFF           | ON             | Update the config file and restart the server  || gtid_mode                        | OFF           | ON             | Update the config file and restart the server  || log_slave_updates                | OFF           | ON             | Update the config file and restart the server  || master_info_repository           | FILE          | TABLE          | Update the config file and restart the server  || relay_log_info_repository        | FILE          | TABLE          | Update the config file and restart the server  || transaction_write_set_extraction | OFF           | XXHASH64       | Update the config file and restart the server  |+----------------------------------+---------------+----------------+------------------------------------------------+Some variables need to be changed, but cannot be done dynamically on the server: an option file is required.Detecting the configuration file...Default file not found at the standard locations.Please specify the path to the MySQL configuration file: /Users/qianyin/sandboxes/multi_msb_5_7_29/node1/my.sandbox.cnfDo you want to perform the required configuration changes? [y/n]: yCluster admin user 'root'@'%' created.Configuring instance...The instance 'node-1:24630' was configured to be used in an InnoDB cluster.NOTE: MySQL server needs to be restarted for configuration changes to take effect.依次修改另外2个节点查看my.cnf 会发现在文件末尾添加了如下配置：binlog_checksum = NONEenforce_gtid_consistency = ONgtid_mode = ONlog_slave_updates = ONmaster_info_repository = TABLErelay_log_info_repository = TABLEtransaction_write_set_extraction = XXHASH64配置完后，检查下MySQL  localhost:24630 ssl  JS &gt; dba.checkInstanceConfiguration('root@localhost:24631')Validating local MySQL instance listening at port 24631 for use in an InnoDB cluster...This instance reports its own address as node-2:24631Checking whether existing tables comply with Group Replication requirements...No incompatible tables detectedChecking instance configuration...Instance configuration is compatible with InnoDB clusterThe instance 'node-2:24631' is valid to be used in an InnoDB cluster.{    "status": "ok"}3个节点都显示”status”: “ok” 即可。创建集群 MySQL  localhost:24630 ssl  JS &gt; var cluster = dba.createCluster('testCluster',{'localAddress':'localhost:25630'})A new InnoDB cluster will be created on instance 'localhost:24630'.Disabling super_read_only mode on instance 'node-1:24630'.Validating instance configuration at localhost:24630...This instance reports its own address as node-1:24630Instance configuration is suitable.WARNING: Instance 'node-1:24630' cannot persist Group Replication configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.Creating InnoDB cluster 'testCluster' on 'node-1:24630'...Adding Seed Instance...Cluster successfully created. Use Cluster.addInstance() to add MySQL instances.At least 3 instances are needed for the cluster to be able to withstand up toone server failure.Adding Instances to an InnoDB Cluster**注意：先配置/etc/hosts **127.0.0.1 node-1127.0.0.1 node-2127.0.0.1 node-3否则报错： MySQL  127.0.0.1:24630 ssl  JS &gt; cluster.addInstance('root@localhost:24631',{'localAddress':'localhost:25631'})Cluster.addInstance: Unknown MySQL server host 'node-1' (0) (MySQL Error 2005)添加集群节点 MySQL  localhost:24630 ssl  JS &gt; cluster.addInstance('root@localhost:24631',{'localAddress':'localhost:25631'})NOTE: The target instance 'node-2:24631' has not been pre-provisioned (GTID set is empty). The Shell is unable to decide whether incremental state recovery can correctly provision it.The safest and most convenient way to provision a new instance is through automatic clone provisioning, which will completely overwrite the state of 'node-2:24631' with a physical snapshot from an existing cluster member. To use this method by default, set the 'recoveryMethod' option to 'clone'.The incremental state recovery may be safely used if you are sure all updates ever executed in the cluster were done with GTIDs enabled, there are no purged transactions and the new instance contains the same GTID set as the cluster or a subset of it. To use this method by default, set the 'recoveryMethod' option to 'incremental'.Please select a recovery method [I]ncremental recovery/[A]bort (default Incremental recovery): Validating instance configuration at localhost:24631...This instance reports its own address as node-2:24631Instance configuration is suitable.WARNING: Instance 'node-2:24631' cannot persist Group Replication configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.A new instance will be added to the InnoDB cluster. Depending on the amount ofdata on the cluster this might take from a few seconds to several hours.Adding instance to the cluster...Monitoring recovery process of the new cluster member. Press ^C to stop monitoring and let it continue in background.State recovery already finished for 'node-2:24631'WARNING: Instance 'node-1:24630' cannot persist configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.The instance 'localhost:24631' was successfully added to the cluster.     MySQL  localhost:24630 ssl  JS &gt; cluster.addInstance('root@localhost:24632',{'localAddress':'localhost:25632'})NOTE: The target instance 'node-3:24632' has not been pre-provisioned (GTID set is empty). The Shell is unable to decide whether incremental state recovery can correctly provision it.The safest and most convenient way to provision a new instance is through automatic clone provisioning, which will completely overwrite the state of 'node-3:24632' with a physical snapshot from an existing cluster member. To use this method by default, set the 'recoveryMethod' option to 'clone'.The incremental state recovery may be safely used if you are sure all updates ever executed in the cluster were done with GTIDs enabled, there are no purged transactions and the new instance contains the same GTID set as the cluster or a subset of it. To use this method by default, set the 'recoveryMethod' option to 'incremental'.Please select a recovery method [I]ncremental recovery/[A]bort (default Incremental recovery): Validating instance configuration at localhost:24632...This instance reports its own address as node-3:24632Instance configuration is suitable.WARNING: Instance 'node-3:24632' cannot persist Group Replication configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.A new instance will be added to the InnoDB cluster. Depending on the amount ofdata on the cluster this might take from a few seconds to several hours.Adding instance to the cluster...Monitoring recovery process of the new cluster member. Press ^C to stop monitoring and let it continue in background.State recovery already finished for 'node-3:24632'WARNING: Instance 'node-1:24630' cannot persist configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.WARNING: Instance 'node-2:24631' cannot persist configuration since MySQL version 5.7.29 does not support the SET PERSIST command (MySQL version &gt;= 8.0.11 required). Please use the &lt;Dba&gt;.configureLocalInstance() command locally to persist the changes.The instance 'localhost:24632' was successfully added to the cluster.查看cluster 状态 MySQL  localhost:24630 ssl  JS &gt; cluster.status(){    "clusterName": "testCluster",     "defaultReplicaSet": {        "name": "default",         "primary": "node-1:24630",         "ssl": "REQUIRED",         "status": "OK",         "statusText": "Cluster is ONLINE and can tolerate up to ONE failure.",         "topology": {            "node-1:24630": {                "address": "node-1:24630",                 "mode": "R/W",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            },             "node-2:24631": {                "address": "node-2:24631",                 "mode": "R/O",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            },             "node-3:24632": {                "address": "node-3:24632",                 "mode": "R/O",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            }        },         "topologyMode": "Single-Primary"    },     "groupInformationSourceMember": "node-1:24630"安装MySQL router待补充模拟单节点重启关闭节点./node2/stopdbdeployer global status# Running "status_all" on multi_msb_5_7_29MULTIPLE  /Users/qianyin/sandboxes/multi_msb_5_7_29node1 : node1 on  -  port       24630 (24630)node2 : node2 off  -  port      24630 (24631)node3 : node3 on  -  port       24632 (24632)集群状态 MySQL  localhost:6447 ssl  JS &gt; dba.getCluster().status(){    "clusterName": "testCluster",     "defaultReplicaSet": {        "name": "default",         "primary": "node-1:24630",         "ssl": "REQUIRED",         "status": "OK_NO_TOLERANCE",         "statusText": "Cluster is NOT tolerant to any failures. 1 member is not active",         "topology": {            "node-1:24630": {                "address": "node-1:24630",                 "mode": "R/W",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            },             "node-2:24631": {                "address": "node-2:24631",                 "mode": "n/a",                 "readReplicas": {},                 "role": "HA",                 "shellConnectError": "MySQL Error 2003 (HY000): Can't connect to MySQL server on 'node-2' (61)",                 "status": "(MISSING)"            },             "node-3:24632": {                "address": "node-3:24632",                 "mode": "R/O",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            }        },         "topologyMode": "Single-Primary"    },     "groupInformationSourceMember": "node-1:24630"}启动节点&gt; ./node2/start.. sandbox server started&gt; dbdeployer global status# Running "status_all" on multi_msb_5_7_29MULTIPLE  /Users/qianyin/sandboxes/multi_msb_5_7_29node1 : node1 on  -  port       24630 (24630)node2 : node2 on  -  port       24631 (24631)node3 : node3 on  -  port       24632 (24632)查看集群状态 MySQL  localhost:6447 ssl  JS &gt; dba.getCluster().status(){    "clusterName": "testCluster",     "defaultReplicaSet": {        "name": "default",         "primary": "node-1:24630",         "ssl": "REQUIRED",         "status": "OK_NO_TOLERANCE",         "statusText": "Cluster is NOT tolerant to any failures. 1 member is not active",         "topology": {            "node-1:24630": {                "address": "node-1:24630",                 "mode": "R/W",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            },             "node-2:24631": {                "address": "node-2:24631",                 "mode": "R/W",                 "readReplicas": {},                 "role": "HA",                 "status": "(MISSING)"            },             "node-3:24632": {                "address": "node-3:24632",                 "mode": "R/O",                 "readReplicas": {},                 "role": "HA",                 "status": "ONLINE"            }        },         "topologyMode": "Single-Primary"    },     "groupInformationSourceMember": "node-1:24630"修复cluster.removeInstance('root@localhost:24631',{force: true})  #这一步可能会失败，多尝试几次cluster.addInstance('root@localhost:24631',{'localAddress':'localhost:25631'})常用运维命令  组复制状态          select * from performance_schema.global_status where variable_name like '%group%';        组复制成员          select * from performance_schema.replication_group_members;      所有节点重启，脑裂场景参考如下https://jeremyxu2010.github.io/2019/05/mysql-innodb-cluster%E5%AE%9E%E6%88%98/]]></content>
      <categories>
        
          <category> 运维 </category>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> innodb_cluster </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[MySQL运维SQL&工具 手册]]></title>
      <url>/%E8%BF%90%E7%BB%B4/mysql/2020/04/18/mysql%E8%BF%90%E7%BB%B4SQL&%E5%B7%A5%E5%85%B7%E9%9B%86%E9%94%A6/</url>
      <content type="text"><![CDATA[连接      如何不需要密码的登录，直接mysql    [mysql]  --表示： 只有mysql命令才能免密码user=rootpassword=123socket=/tmp/mysql.sock   [mysqladmin] --表示： 只有mysqladmin命令才能免密码user=rootpassword=123socket=/tmp/mysql.sock[mysqldump] --表示： 只有mysqldump命令才能免密码user=rootpassword=123socket=/tmp/mysql.sock[client]   --表示：只要是客户端的命令，都是可以免密码的user=rootpassword=123socket=/tmp/mysql.sock      MySQL如何查看用户名密码      MySQL5.7.6之前    1. show grants for $user;2. select host,user,Password from user;            MySQL5.7.6+    select host,user,authentication_string,password_lifetime,password_expired,password_last_changed from mysql.user where user='xxx';      information_schema相关如何在线kill掉满足某种条件的session待补充PROCESSLIST      分析出当前连接过来的客户端ip的分布情况    select substring_index(host,':', 1) as appip ,count(*) as count from information_schema.PROCESSLIST group by appip order by count desc;            分析处于Sleep状态的连接分布情况    select substring_index(host,':', 1) as appip ,count(*) as count from information_schema.PROCESSLIST where COMMAND='Sleep' group by appip order by count desc ;            分析哪些DB访问的比较多    select DB ,count(*) as count from information_schema.PROCESSLIST where COMMAND='Sleep' group by DB order by count desc ;            分析哪些用户访问的比较多    select user ,count(*) as count from information_schema.PROCESSLIST where COMMAND='Sleep' group by user order by count desc ;      Tables      列出大于10G以上的表    select TABLE_SCHEMA,TABLE_NAME,TABLE_ROWS,ROUND((INDEX_LENGTH+DATA_FREE+DATA_LENGTH)/1024/1024/1024) as size_G from information_schema.tables where ROUND((INDEX_LENGTH+DATA_FREE+DATA_LENGTH)/1024/1024/1024) &gt; 10 order by size_G desc ;      performance_schema相关performance_schema 状态概览SHOW VARIABLES LIKE 'perf%';SHOW STATUS LIKE 'perf%';SHOW ENGINE PERFORMANCE_SCHEMA STATUS;如何查看每个threads当前session变量的值select * from performance_schema.variables_by_thread as a,(select THREAD_ID,PROCESSLIST_ID,PROCESSLIST_USER,PROCESSLIST_HOST,PROCESSLIST_COMMAND,PROCESSLIST_STATE from performance_schema.threads where PROCESSLIST_USER&lt;&gt;'NULL') as b where a.THREAD_ID = b.THREAD_ID and a.VARIABLE_NAME = 'sql_safe_updates'TOP SQL 相关  能够解决什么问题： 可以找到某个表是否还有业务访问？能够解决什么问题： 可以确定某个库，某个表的业务是否迁移干净？能够解决什么问题： 可以用于分析业务是否异常？能够解决什么问题： 根据TopN 可以分析压力？能够解决什么问题： 可以用于分析哪些表是热点数据，这些TopN的表才是值得优化的表。只要每一条语句快0.01ms，那么1亿条呢？      一个实例中查询最多的TopN SQL    select SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN  from performance_schema.events_statements_summary_by_digest where DIGEST_TEXT like 'select%' and DIGEST_TEXT not like '%SESSION%' order by COUNT_STAR desc limit 10\G            一个实例中写入最多的TopN SQL    select SCHEMA_NAME,DIGEST_TEXT,COUNT_STAR,FIRST_SEEN,LAST_SEEN  from performance_schema.events_statements_summary_by_digest where DIGEST_TEXT like 'insert%' or DIGEST_TEXT like 'update%'or DIGEST_TEXT like 'delete%' or DIGEST_TEXT like 'replace%'  order by COUNT_STAR desc limit 10\G      Table IO 相关的监控库级别      如何查看一个MySQL实例中哪个库的all latency时间最大              ]]></content>
      <categories>
        
          <category> 运维 </category>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 运维 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[用innobackupex实现加密备份]]></title>
      <url>/mysql/2020/04/18/innobackupex_encrypt/</url>
      <content type="text"><![CDATA[安装innobackupexyum install https://repo.percona.com/yum/percona-release-latest.noarch.rpmyum install percona-xtrabackup-24MySQL创建备份用户GRANT RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO 'xbackupopr'@'%' IDENTIFIED BY 'UFfrBrtyv_cxR50C';生成encrypt-key（可不执行，直接用脚本中的key）openssl enc -aes-256-cbc -pass pass:Password -P -md sha1 | grep iv | cut -d'=' -f2 脚本#!/usr/bin/python#coding:UTF-8import os,time,sys,commandsinnobackupex = '/usr/bin/innobackupex'# 全备函数def full_backup(host, port, user, password, full_backup_dir,week_of_dir, backup_log):    os.system("%s --host=%s --port=%s --user=%s --password=%s --encrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7 --extra-lsndir=%s --no-timestamp %s &gt; %s 2&gt;&amp;1" %(innobackupex,host, port, user, password, week_of_dir,full_backup_dir, backup_log))# 增备函数def incr_backup(host, port, user, password, incr_backup_dir, incremental_lsn,extra_lsndir,backup_log):    os.system("%s --incremental %s  --incremental-lsn=%s --host=%s --port=%s --user=%s --password=%s  --extra-lsndir=%s --encrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7 &gt; %s 2&gt;&amp;1" %(innobackupex,incr_backup_dir,incremental_lsn,host,port,user,password,extra_lsndir,backup_log))# 主函数if __name__ == '__main__':    host = "127.0.0.1"    port = '3306'    user = 'xbackupopr'    password = 'UFfrBrtyv_cxR50C'    backup_dir = '/data/backup/'    defaults_file = '/data/my3306/my.cnf'    wday = time.localtime().tm_wday    week_of_dir = backup_dir + time.strftime("%U", time.localtime())    full_backup_dir = week_of_dir + '/full'    backup_log = "/tmp/backup.log"    # 增备寻找最新的上一次备份的基准目录    base_backup_dir = commands.getoutput('find ' + week_of_dir + ' -mindepth 1 -maxdepth 1 -type d -printf "%P\n"  | sort -nr | head -1')     # 获取最新的lsn,xtrabackup_checkpoints文件在每次全备或者增备后会被覆盖    if os.path.exists(week_of_dir + '/xtrabackup_checkpoints'):        incremental_lsn = commands.getoutput('cat ' + week_of_dir + '/xtrabackup_checkpoints| grep to_lsn | cut -d"=" -f2|sed -e "s/^[ ]*//g"')        print(incremental_lsn)    else:        print('xtrabackup_checkpoints not exists.Maybe full_backup progress not running yet.')    # 探测mysql实例是否存活，如果存活继续下面的程序执行，如果不存活则直接退出程序    mysql_stat = commands.getoutput('/bin/netstat -anp|grep ' + port + ' |grep -v unix|wc -l')    if mysql_stat &gt;= 1:        print "mysql实例存活，可进行备份操作！"    else:        print "mysql实例不存在，备份操作终止！"        sys.exit()    # 每周生成一个周备份目录，全备和增备目录都放在此目录下面    if os.path.exists(week_of_dir):        print "周备份目录已经生成，可进行相应的全备或者增量备份"    else:        print "周备份目录未产生，创建周备份目录..."        os.makedirs(week_of_dir)    # 判断是否周日，如果是周日，直接进行全备，如果不是周日，先检查全备是否存在，不存在则进行全备，存在则进行增备    print "备份开始"    if wday == 6:        full_backup(host, port, user, password, full_backup_dir, week_of_dir,backup_log)    else:        if os.path.exists(full_backup_dir):            incr_backup(host, port, user, password, week_of_dir,incremental_lsn,week_of_dir,backup_log)        else:            full_backup(host, port, user, password, full_backup_dir,week_of_dir, backup_log)    print "备份结束，判断备份是否成功"    try:        with open("/tmp/backup.log") as f:            f.seek(-14, 2)            backup_results = f.readline().strip()            if backup_results == "completed OK!":                print "备份成功"            else:                print "备份失败"                except Error:        sys.exit()    # 备份保留4周    os.system("find %s -mindepth 1 -maxdepth 1 -type d -ctime +28 -exec rm -rf  {} \;" %backup_dir) 备份解密innobackupex  --decrypt=AES256 --encrypt-key=CCD0C542F643163CBF4734362FC917C7  /data/backup/42/full/]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> pt-tools </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb change stream 功能介绍]]></title>
      <url>/mongodb/2020/03/03/mongodb_change_stream/</url>
      <content type="text"><![CDATA[什么是 Change StreamChange Stream 是 MongoDB 用于实现变更追踪的解决方案，类似于关系数据库的触发器，但原理不完全相同:                   Change Stream      触发器                  触发方式      异步      同步              触发位置      应用回调事件      数据库触发器              触发次数      每个订阅事件的客户端      1次              故障恢复      从上次断点重新触发      事务回滚      Change Stream 的实现原理Change Stream 是基于 oplog 实现的。它在 oplog 上开启一个 tailable cursor 来追踪所有复制集上的变更操作，最终调用应用中定义的回调函数。被追踪的变更事件主要包括:  insert/update/delete:插入、更新、删除;  drop:集合被删除;  rename:集合被重命名;  dropDatabase:数据库被删除;  invalidate:drop/rename/dropDatabase将导致invalidate被触发， 并关闭 change stream;Change Stream 与可重复读Change Stream 只推送已经在大多数节点上提交的变更操作。即“可重复读”的变更。 这个验证是通过 {readConcern: "majority"} 实现的。因此:  未开启majorityreadConcern的集群无法使用ChangeStream;  当集群无法满足{w:"majority"}时，不会触发ChangeStream(例如PSA架构中的 S 因故障宕机)。Change Stream 变更过滤如果只对某些类型的变更事件感兴趣，可以使用使用聚合管道的过滤步骤过滤事件。例如:var cs = db.collection.watch([{    $match: {        operationType: {            $in: ['insert', 'delete']} }}])Change Stream 示例开启2个窗口:在窗口1执行监听：rs0:PRIMARY&gt; db.test.watch([],{maxAwaitTimeMS: 30000}).pretty(){        "_id" : {                "_data" : "825EA7A400000000012B022C0100296E5A1004124DEBF980784545948639CB6F3A779146645F696400645EA7A400604B3753349DDA300004"        },        "operationType" : "insert",        "clusterTime" : Timestamp(1588044800, 1),        "fullDocument" : {                "_id" : ObjectId("5ea7a400604b3753349dda30"),                "x" : 1        },        "ns" : {                "db" : "test",                "coll" : "test"        },        "documentKey" : {                "_id" : ObjectId("5ea7a400604b3753349dda30")        }}窗口2 执行插入：rs0:PRIMARY&gt; db.test.insert({x:1})WriteResult({ "nInserted" : 1 })此刻窗口1会同步如下：{        "_id" : {                "_data" : "825EA7A400000000012B022C0100296E5A1004124DEBF980784545948639CB6F3A779146645F696400645EA7A400604B3753349DDA300004"        },        "operationType" : "insert",        "clusterTime" : Timestamp(1588044800, 1),        "fullDocument" : {                "_id" : ObjectId("5ea7a400604b3753349dda30"),                "x" : 1        },        "ns" : {                "db" : "test",                "coll" : "test"        },        "documentKey" : {                "_id" : ObjectId("5ea7a400604b3753349dda30")        }}这个功能跟gh-ost是不是有点神似？^_^Change Stream 故障恢复想要从上次中断的地方继续获取变更流，只需要保留上次变更通知中的 id 即可。例如:var cs = db.collection.watch([], {resumeAfter: &lt;_id&gt;}) 即可从上一条通知中断处继续获取后续的变更通知。Change Stream 使用场景  跨集群的变更复制:在源集群中订阅ChangeStream，一旦得到任何变更立即写入目标集群。  微服务联动:当一个微服务变更数据库时，其他微服务得到通知并做出相应的变 更。  其他任何需要系统联动的场景。注意事项  ChangeStream依赖于oplog，因此中断时间不可超过oplog回收的最大时间窗;  在执行update操作时，如果只更新了部分数据，那么ChangeStream通知的也是增量部分；  删除数据时通知的仅是删除数据的_id。]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb 多文档事务]]></title>
      <url>/mongodb/2020/02/21/mongodb%E4%BA%8B%E5%8A%A1/</url>
      <content type="text"><![CDATA[  MongoDB 虽然已经在 4.2 开始全面支持了多文档事务，但并不代表大家应该毫无节制地使用它。相反，对事务的使用原则应该是:能不用尽量不用。  通过合理地设计文档模型，可以规避绝大部分使用事务的必要性为什么?  事务 = 锁，节点协调，额外开销，性能影响MongoDB ACID 多文档事务支持            事务属性      支持程度                  Atomocity 原子性（要么提交要么回滚。没什么嘻嘻哈哈）      单表单行 : 1.x 就支持复制集多表多行:4.0 复制集 分片集群多表多行4.2              Consistency 一致性（分布式数据库中更关注各个节点之间的一致性）      writeConcern, readConcern (3.2)              Isolation 隔离性（读到的数据是脏读吗？这个数据还会回滚吗？）      readConcern (3.2)              Durability 持久性（server宕机后数据还在吗？）      Journal and Replication      使用方法MongoDB 多文档事务的使用方式与关系数据库非常相似:try (ClientSession clientSession = client.startSession()) { 	clientSession.startTransaction();   collection.insertOne(clientSession, docOne);   collection.insertOne(clientSession, docTwo);   clientSession.commitTransaction();}事务的隔离级别  事务完成前，事务外的操作对该事务所做的修改不可访问  如果事务内使用 {readConcern: "snapshot"}，则可以达到可重复读Repeatable Read实验:启用事务后的隔离性rs0:PRIMARY&gt; db.tx.insertMany([{x:1},{x:2}]){        "acknowledged" : true,        "insertedIds" : [                ObjectId("5ea76e930bdbce8957fc4708"),                ObjectId("5ea76e930bdbce8957fc4709")        ]}rs0:PRIMARY&gt; db.tx.find(){ "_id" : ObjectId("5ea76e930bdbce8957fc4708"), "x" : 1 }{ "_id" : ObjectId("5ea76e930bdbce8957fc4709"), "x" : 2 }rs0:PRIMARY&gt; var session = db.getMongo().startSession()rs0:PRIMARY&gt; session.startTransaction()rs0:PRIMARY&gt; var coll = session.getDatabase("test").getCollection("tx")rs0:PRIMARY&gt; coll.update({x:1},{$set:{y:1}})WriteResult({ "nMatched" : 1, "nUpserted" : 0, "nModified" : 1 })rs0:PRIMARY&gt; coll.find(){ "_id" : ObjectId("5ea76e930bdbce8957fc4708"), "x" : 1, "y" : 1 }{ "_id" : ObjectId("5ea76e930bdbce8957fc4709"), "x" : 2 }rs0:PRIMARY&gt; db.tx.find(){ "_id" : ObjectId("5ea76e930bdbce8957fc4708"), "x" : 1 }{ "_id" : ObjectId("5ea76e930bdbce8957fc4709"), "x" : 2 }rs0:PRIMARY&gt; session.commitTransaction()rs0:PRIMARY&gt; db.tx.find(){ "_id" : ObjectId("5ea76e930bdbce8957fc4708"), "x" : 1, "y" : 1 }{ "_id" : ObjectId("5ea76e930bdbce8957fc4709"), "x" : 2 }由上可见，事务内的更新对事务外的更新是不可见的。同样，事务外的更新对事务内的更新也是不可见的。（试验过程略）事务写机制MongoDB 的事务错误处理机制不同于关系数据库:      当一个事务开始后，如果事务要修改的文档在事务外部被修改过，则事务修改这个文档时会触发 Abort 错误，因为此时的修改冲突了;    我们开2个窗口验证下：    窗口1：    rs0:PRIMARY&gt; coll.find(){ "_id" : ObjectId("5ea76e930bdbce8957fc4708"), "x" : 1, "y" : 13 }{ "_id" : ObjectId("5ea76e930bdbce8957fc4709"), "x" : 2 }rs0:PRIMARY&gt; var session = db.getMongo().startSession();session.startTransaction({ readConcern: {level: "snapshot"}, writeConcern: {w: "majority"}});var coll = session.getDatabase('test').getCollection("tx");rs0:PRIMARY&gt; coll.updateOne({x: 1}, {$set: {y: 12}});{ "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }        窗口2：    rs0:PRIMARY&gt; var session = db.getMongo().startSession();session.startTransaction({ readConcern: {level: "snapshot"}, writeConcern: {w: "majority"}});var coll = session.getDatabase('test').getCollection("tx");rs0:PRIMARY&gt; coll.updateOne({x: 1}, {$set: {y: 12}});2020-04-28T10:17:24.681+0800 E  QUERY    [js] uncaught exception: WriteCommandError({        "errorLabels" : [                "TransientTransactionError"        ],        "operationTime" : Timestamp(1588040236, 1),        "ok" : 0,        "errmsg" : "WriteConflict",        "code" : 112,        "codeName" : "WriteConflict",        "$clusterTime" : {                "clusterTime" : Timestamp(1588040236, 1),                "signature" : {                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),                        "keyId" : NumberLong(0)                }        }}) :WriteCommandError({        "errorLabels" : [                "TransientTransactionError"        ],        "operationTime" : Timestamp(1588040236, 1),        "ok" : 0,        "errmsg" : "WriteConflict",        "code" : 112,        "codeName" : "WriteConflict",        "$clusterTime" : {                "clusterTime" : Timestamp(1588040236, 1),                "signature" : {                        "hash" : BinData(0,"AAAAAAAAAAAAAAAAAAAAAAAAAAA="),                        "keyId" : NumberLong(0)                }        }})WriteCommandError@src/mongo/shell/bulk_api.js:417:48executeBatch@src/mongo/shell/bulk_api.js:915:23Bulk/this.execute@src/mongo/shell/bulk_api.js:1163:21DBCollection.prototype.updateOne@src/mongo/shell/crud_api.js:600:17@(shell):1:1        可以看到报错信息：WriteConflict          那如果这个时候我在窗口1中提交事务，窗口2能修改吗？答案是不能，因为窗口2的事务还在之前的状态，这个时候可以先回滚窗口2的事务，然后再提交执行即可。            如果一个事务已经开始修改一个文档，在事务以外尝试修改同一个文档，则事务以 外的修改会等待事务完成才能继续进行(write-wait.md实验)    同样我们开2个窗口，窗口1启动事务，然后更新数据。    rs0:PRIMARY&gt; var session = db.getMongo().startSession();session.startTransaction({ readConcern: {level: "snapshot"}, writeConcern: {w: "majority"}});var coll = session.getDatabase('test').getCollection("tx");rs0:PRIMARY&gt; coll.updateOne({x: 1}, {$set: {y: 11}});{ "acknowledged" : true, "matchedCount" : 1, "modifiedCount" : 1 }        窗口2在事务外尝试修改数据，可以发现窗口2会hung住，直到窗口1的事务提交。这里其实跟MySQL做法一样，因为在主键上有了行锁，所以肯定会有锁等待。  注意事项  可以实现和关系型数据库类似的事务场景;  必须使用与MongoDB4.2兼容的驱动;  事务默认必须在60秒(可调)内完成，否则将被取消;（类似MySQL中的wait_timeout）  涉及事务的分片不能使用仲裁节点;（仲裁节点的又一缺陷）  事务会影响chunk迁移效率。正在迁移的chunk也可能造成事务提交失败(重试即可);（不建议用事务的原因）  多文档事务中的读操作必须使用主节点读;（类似MySQL中不能跨主从去join）  readConcern只应该在事务级别设置，不能设置在每次读写操作上。（类似不建议MySQL中每次连接中设置trx_isolation级别）]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb writeConcern初探]]></title>
      <url>/mongodb/2020/02/10/mongodb-writeConcern/</url>
      <content type="text"><![CDATA[什么是writeConcernwriteConcern 决定一个写操作落到多少个节点上才算成功。取值包括：  0 ：发起写操作，不关心是否成功。  1~集群最大节点数 ：写操作需要复制到指定节点数才算成功  majority：写操作需要复制到多数节点才算成功发起写操作的程序将阻塞直到满足上诉条件。  writeConcern类似MySQL的半同步复制--rpl-semi-sync-master-wait-for-slave-count这里还要提到另一个概念：Journal 日志，跟MySQL的redo log类似，也是为了做crash safe。为了保证每次写数据都落盘，可以指定j: true注：3.2之前只要primary节点落盘就确认ok，3.2之后需要w:N都确认才okwriteConcern功能验证w: “majority”rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: "majority"}})WriteResult({ "nInserted" : 1 })这是推荐的写法，mongodb会自己判断只要写入多数节点即返回成功w: 节点数rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3 }})WriteResult({ "nInserted" : 1 })可以看到正常情况下（secondary节点没延迟）也很快返回成功了。w＞节点数rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 4}})WriteResult({        "nInserted" : 1,        "writeConcernError" : {                "code" : 100,                "codeName" : "UnsatisfiableWriteConcern",                "errmsg" : "Not enough data-bearing nodes"        }})这里虽然报错了，但实际还是写入成功了。secondary节点有延迟的情况下，观察现象首先我们模拟延迟场景，在primary节点执行，模拟secondary 2节点延迟10秒conf=rs.conf() conf.members[2].slaveDelay = 10conf.members[2].priority = 0 rs.reconfig(conf)观察复制延迟下的写入，以及timeout参数db.test.insert( {count: 1}, {writeConcern: {w: 3}})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3}})# 这里会等待10sWriteResult({ "nInserted" : 1 })rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }db.test.insert( {count: 1}, {writeConcern: {w: 3, wtimeout:3000 }})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }rs0:PRIMARY&gt; db.test.insert( {count: 1}, {writeConcern: {w: 3, wtimeout:3000 }})# 这里等3s后报错，实际命令敲下的一瞬间已写入到primary和没延迟的secondary，延迟节点需要等10s后落盘。WriteResult({        "nInserted" : 1,        "writeConcernError" : {                "code" : 64,                "codeName" : "WriteConcernFailed",                "errmsg" : "waiting for replication timed out",                "errInfo" : {                        "wtimeout" : true                }        }})rs0:PRIMARY&gt; db.test.find(){ "_id" : ObjectId("5e9d7bf6d4eb493af10599c9"), "count" : 1 }{ "_id" : ObjectId("5e9d7cf4d4eb493af10599ca"), "count" : 1 }{ "_id" : ObjectId("5e9d7e2ad4eb493af10599cb"), "count" : 1 }{ "_id" : ObjectId("5e9d7f9ad4eb493af10599cc"), "count" : 1 }{ "_id" : ObjectId("5e9d800ed4eb493af10599cd"), "count" : 1 }总结  虽然多于半数的writeConcern都是安全的，但通常只会设置majority，因为这是等待写入延迟时间最短的选择;  不要设置writeConcern等于总节点数，因为一旦有一个节点故障，所有写操作都将失败;  writeConcern虽然会增加写操作延迟时间，但并不会显著增加集群压力，因此无论是否等待，写操作最终都会复制到所有节点上。设置 writeConcern 只是让写操作等待复制后再返回而已;  应对重要数据应用{w:“majority”}，普通数据可以应用{w:1}以确保最佳性能。]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb readPreference 和 readConcern初探]]></title>
      <url>/mongodb/2020/01/03/mongodb-readPreference&readConcern/</url>
      <content type="text"><![CDATA[综述在读取数据的过程中我们需要关注以下两个问题:  从哪里读?  什么样的数据可以读?第一个问题是是由 readPreference 来解决 第二个问题则是由 readConcern 来解决什么是 readPreferencereadPreference 决定使用哪一个节点来满足 正在发起的读请求。可选值包括:  primary:只选择主节点;  primaryPreferred:优先选择主节点，如果不可用则选择从节点;  secondary:只选择从节点;  secondaryPreferred:优先选择从节点， 如果从节点不可用则选择主节点;  nearest:选择最近的节点;readPreference 场景举例  primary/primaryPreferred 用户下订单后马上将用户转到订单详情页,因为此时从节点可能还没复制到新订单;  secondary/secondaryPreferred 用户查询自己下过的订单。查询历史订单对 时效性通常没有太高要求;  secondary 生成报表。报表对时效性要求不高，但资源需求大，可以在从节点 单独处理，避免对线上用户造成影响;  nearest将用户上传的图片分发到全世界，让各地用户能够就近读取。每个地区 的应用选择最近的节点读取数据。readPreference 与 TagreadPreference 只能控制使用一类节点。Tag 则可以将节点选择控制 到一个或几个节点。考虑以下场景:  一个5个节点的复制集;  3个节点硬件较好，专用于服务线上客户;  2个节点硬件较差，专用于生成报表可以使用 Tag 来达到这样的控制目的:  为3个较好的节点打上{purpose:”online”};  为2个较差的节点打上{purpose:”analyse”};  在线应用读取时指定online，报表读取时指定analyse。readPreference 配置通过 MongoDB 的连接串参数:  mongodb://host1:27107,host2:27107,host3:27017/?replicaSet=rs&amp;readPre ference=secondary通过 MongoDB 驱动程序 API:  MongoCollection.withReadPreference(ReadPreferencereadPref)Mongo Shell:  db.collection.find({}).readPref(“secondary”)readPreference注意事项  指定readPreference时也应注意高可用问题。例如将readPreference指定primary，则发生故障转移不存在 primary 期间将没有节点可读。如果业务允许，则应选择 primaryPreferred;  使用Tag时也会遇到同样的问题，如果只有一个节点拥有一个特定Tag，则在这个节点失效时将无节点可读。这在有时候是期望的结果，有时候不是。例如:          如果报表使用的节点失效，即使不生成报表，通常也不希望将报表负载转移到其他节点上，此时只有一个节点有报表 Tag 是合理的选择;      如果线上节点失效，通常希望有替代节点，所以应该保持多个节点有同样的Tag;        Tag有时需要与优先级、选举权综合考虑。例如做报表的节点通常不会希望它成为主节点，则优先级应为 0。什么是 readConcern在 readPreference 选择了指定的节点后，readConcern 决定这个节点上的数据哪些 是可读的，类似于关系数据库的隔离级别。可选值包括:  available:读取所有可用的数据;  local:读取所有可用且属于当前分片的数据;  majority:读取在大多数节点上提交完成的数据;  linearizable:可线性化读取文档;  snapshot:读取最近快照中的数据;readConcern: local 和 available在复制集中 local 和 available 是没有区别的。两者的区别主要体现在分片集上。考虑以下场景:  一个chunkx正在从shard1向shard2迁移;  整个迁移过程中chunkx中的部分数据会在shard1和shard2中同时存在，但源分片shard1仍然是 chunk x 的负责方:          所有对chunkx的读写操作仍然进入shard1;      config中记录的信息chunkx仍然属于shard1;        此时如果读shard2，则会体现出local和available的区别:          local:只取应该由shard2负责的数据(不包括x);      available:shard2上有什么就读什么(包括x);      注意事项:  虽然看上去总是应该选择local，但毕竟对结果集进行过滤会造成额外消耗。在一些无关紧要的场景(例如统计)下，也可以考虑 available;  MongoDB&lt;=3.6不支持对从节点使用{readConcern:”local”};  从主节点读取数据时默认readConcern是local，从从节点读取数据时默认 readConcern 是 available(向前兼容原因)。readConcern: majority 与脏读如果在一次写操作到达大多数节点前读取了这个写操作，然后因为系统故障该操作回滚了，则发生了脏读问题;使用 {readConcern: “majority”} 可以有效避免脏读readConcern: 如何实现安全的读写分离考虑如下场景:  向主节点写入一条数据;  立即从从节点读取这条数据。  如何保证自己能够读到刚刚写入的数据?下述方式有可能读不到刚写入的订单db.orders.insert({ oid: 101, sku: ”kite", q: 1}) db.orders.find({oid:101}).readPref("secondary")使用 writeConcern + readConcern majority 来解决db.orders.insert({ oid: 101, sku: "kiteboar", q: 1}, {writeConcern:{w: "majority”}}) db.orders.find({oid:101}).readPref("secondary").readConcern("majority")]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mongodb复制集环境搭建]]></title>
      <url>/mongodb/2019/03/20/mongo_replset_building/</url>
      <content type="text"><![CDATA[  目标：在mac上部署3个节点的复制集，为后续测试准备环境创建目录：mkdir -p /data/mongodb/db{1,2,3}编辑配置文件：cat /data/mongodb/db1/mongod.conf systemLog:    destination: file    path: /data/mongodb/db1/mongod.log    logAppend: truestorage:    dbPath: /data/mongodb/db1net:    bindIp: 0.0.0.0    port: 28017replication:    replSetName: rs0processManagement:    fork: true  其他节点只需修改path和port即可启动mongod：mongod -f /data/db1/mongod.conf配置复制集：mongo --port 28017  方法一&gt; rs.initiate()&gt; rs.add("HOSTNAME:28018") &gt; rs.add("HOSTNAME:28019")  方法二mongo --port 28017&gt; rs.initiate({    _id: "rs0",    members: [    {_id: 0,host: "localhost:28017" },    {_id: 1,host: "localhost:28018" },    {_id: 2,host: "localhost:28019" }    ]})验证  MongoDB 主节点进行写入mongo localhost:28017&gt; db.test.insert({ a:1 })&gt; db.test.insert({ a:2 });  MongoDB 从节点进行读mongo localhost:28018&gt; rs.slaveOk()&gt; db.test.find()]]></content>
      <categories>
        
          <category> mongodb </category>
        
      </categories>
      <tags>
        
          <tag> mongodb </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[10 | MySQL为什么有时候会选错索引？]]></title>
      <url>/mysql/2019/01/16/MySQL45-9/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[11 | 怎么给字符串字段加索引？]]></title>
      <url>/mysql/2019/01/16/MySQL45-10/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[09 | 普通索引和唯一索引，应该怎么选择？]]></title>
      <url>/mysql/2019/01/13/MySQL45-8/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[08 | 事务到底是隔离的还是不隔离的？]]></title>
      <url>/mysql/2019/01/10/MySQL45-7/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[07 | 行锁功过：怎么减少行锁对性能的影响？]]></title>
      <url>/mysql/2019/01/08/MySQL45-6/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[06 | 全局锁和表锁 ：给表加个字段怎么有这么多阻碍？]]></title>
      <url>/mysql/2019/01/07/MySQL45-5/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[04-05 | 深入浅出索引]]></title>
      <url>/mysql/2019/01/04/MySQL45-4/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[03 | 事务隔离：为什么你改了我还看不见？]]></title>
      <url>/mysql/2019/01/03/MySQL45-3/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[02 | 日志系统：一条SQL更新语句是如何执行的？]]></title>
      <url>/mysql/2019/01/02/MySQL45-2/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[01 | 基础架构：一条SQL查询语句是如何执行的？]]></title>
      <url>/mysql/2019/01/01/MySQL45-1/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
          <tag> 丁奇MySQL45讲 </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
